#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
@Time   : 10/21/25
@Author : guojarrett@gmail.com
@File   : processor.py
"""
import io
import time
import wave
from typing import TYPE_CHECKING, Dict, Any

import numpy as np
from langchain_openai import ChatOpenAI

from src.core.agent.agents.planner_agent import PlannerAgent
from src.core.agent.entities.agent_entity import AgentConfig
from src.utils.logger import logger

if TYPE_CHECKING:
    from src.core.assistant import VoiceAssistant


class CommandProcessor:
    """å‘½ä»¤å¤„ç†å™¨ - è´Ÿè´£å¤„ç†ç”¨æˆ·æŒ‡ä»¤"""

    def __init__(self, assistant: 'VoiceAssistant'):
        self.assistant = assistant
        self.config = assistant.config
        self.planner_agent = None  # PlannerAgent å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰

    def process_command(self):
        """å¤„ç†ç”¨æˆ·æŒ‡ä»¤çš„ä¸»æµç¨‹"""
        self.assistant.is_processing = True

        try:
            # æš‚åœå”¤é†’è¯æ£€æµ‹,é¿å…éº¦å…‹é£å†²çª
            logger.info("â¸ï¸  Pausing wake word detection...")
            self.assistant.detector.pause()

            # ç­‰å¾…ä¸€å°æ®µæ—¶é—´,ç¡®ä¿éº¦å…‹é£é‡Šæ”¾
            time.sleep(0.2)

            # 1. å½•éŸ³
            audio_data = self._record_audio()
            if audio_data is None:
                logger.warning("âš ï¸  å½•éŸ³è¢«å–æ¶ˆæˆ–æ—¶é•¿ä¸è¶³ï¼Œè·³è¿‡å¤„ç†")
                return

            # 2. è¯­éŸ³è¯†åˆ« (ASR)
            text = self._transcribe_audio(audio_data)
            if not text:
                return

            logger.info(f"ğŸ“ Recognized text: {text}")

            # 3. ç†è§£æ„å›¾å¹¶è§„åˆ’ä»»åŠ¡ï¼ˆä½¿ç”¨ PlannerAgentï¼‰
            plan_result = self._understand_and_plan(text)

            # 4. æ‰§è¡Œä»»åŠ¡è®¡åˆ’
            execution_result = self._execute_plan(plan_result)

            # 5. è¯­éŸ³åé¦ˆ
            self._text_to_speech(execution_result)

            logger.info("âœ… Processing completed")

        except Exception as e:
            logger.error(f"âŒ Processing failed: {e}")
            import traceback
            traceback.print_exc()

        finally:
            self.assistant.is_processing = False

            # ç­‰å¾…å½•éŸ³å™¨å®Œå…¨é‡Šæ”¾èµ„æº
            time.sleep(0.3)

            # æ¢å¤å”¤é†’è¯æ£€æµ‹
            logger.info("â–¶ï¸  Resuming wake word detection...")
            self.assistant.detector.resume()

            logger.info("ğŸ¤ Listening for wake words...\n")

    def _record_audio(self) -> bytes:
        """å½•åˆ¶éŸ³é¢‘ï¼ˆæ”¯æŒåŠ¨æ€æ—¶é•¿ï¼‰"""
        logger.info("ğŸ™ï¸  Please speak your command...")
        min_duration = self.config.get("recording.dynamic.min_duration", 2.0)
        max_duration = self.config.get("recording.dynamic.max_duration", 60.0)
        silence_threshold = self.config.get("recording.dynamic.silence_threshold", 500.0)
        silence_duration = self.config.get("recording.dynamic.silence_duration", 3.0)
        speech_threshold = self.config.get("recording.dynamic.speech_threshold", 800.0)
        min_speech_chunks = self.config.get("recording.dynamic.min_speech_chunks", 5)

        audio_data = self.assistant.recorder.record_with_silence_detection(
            min_duration=min_duration,
            max_duration=max_duration,
            silence_threshold=silence_threshold,
            silence_duration=silence_duration,
            speech_threshold=speech_threshold,
            min_speech_chunks=min_speech_chunks
        )

        return audio_data

    def _transcribe_audio(self, audio_data: bytes) -> str:
        """è¯­éŸ³è¯†åˆ«"""
        logger.info("ğŸ”„ Converting speech to text...")

        # æ£€æŸ¥éŸ³é¢‘èƒ½é‡,è¿‡æ»¤æ‰çº¯é™éŸ³
        if not self._has_valid_speech(audio_data):
            logger.warning("âš ï¸  Audio contains only silence or noise, skipping transcription")
            return ""

        if self.assistant.asr_provider == "whisper":
            # æœ¬åœ° Whisper
            result = self.assistant.asr_client.transcribe_from_bytes(
                audio_data=audio_data,
                audio_format="wav",
                language=self.assistant.asr_language
            )
            return result.get("text", "").strip()

        elif self.assistant.asr_provider == "qiniu":
            # ä¸ƒç‰›äº‘ ASR
            result = self.assistant.asr_client.transcribe(audio_data)
            return result.get("text", "").strip()

        return ""

    def _has_valid_speech(self, audio_data: bytes) -> bool:
        """æ£€æŸ¥éŸ³é¢‘æ˜¯å¦åŒ…å«æœ‰æ•ˆè¯­éŸ³"""

        try:
            # å°† bytes è½¬æ¢ä¸ºéŸ³é¢‘æ•°ç»„
            with wave.open(io.BytesIO(audio_data), 'rb') as wav_file:
                frames = wav_file.readframes(wav_file.getnframes())
                audio_array = np.frombuffer(frames, dtype=np.int16)

            # è®¡ç®—èƒ½é‡
            energy = np.sqrt(np.mean(audio_array.astype(float) ** 2))

            # èƒ½é‡é˜ˆå€¼
            energy_threshold = 100.0

            return energy > energy_threshold

        except Exception as e:
            logger.warning(f"âš ï¸ Failed to check audio validity: {e}")
            return True

    def _understand_and_plan(self, text: str) -> Dict[str, Any]:
        """
        ç†è§£æ„å›¾å¹¶ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ï¼ˆä½¿ç”¨ PlannerAgentï¼‰

        å‚æ•°:
            text: ç”¨æˆ·çš„è¯­éŸ³è¯†åˆ«æ–‡æœ¬

        è¿”å›:
            åŒ…å«è®¡åˆ’çš„å­—å…¸
        """
        logger.info("ğŸ§  Understanding intent and planning...")

        # 1. åˆå§‹åŒ– PlannerAgent
        if self.planner_agent is None:
            self.planner_agent = self._initialize_planner_agent()

        # todo å¦‚æœå¤±è´¥ï¼Œè°ƒç”¨ttsæ¨¡å‹è¾“å‡º
        # if self.planner_agent is None:

        # 3. ä½¿ç”¨ PlannerAgent ç”Ÿæˆè®¡åˆ’
        try:
            plan_result = self.planner_agent.plan_task(text)
            logger.info(f"ğŸ“‹ Plan generated: {plan_result.get('plan', {}).get('feasibility', 'unknown')}")

            logger.info("Plan Details:", plan_result.get("plan", {}))

            return plan_result

        except Exception as e:
            logger.error(f"âŒ Planning failed: {e}")
            return {
                "success": False,
                "message": f"è§„åˆ’ä»»åŠ¡æ—¶å‡ºé”™: {str(e)}",
                "plan": {
                    "task": text,
                    "feasibility": "error",
                    "steps": []
                }
            }

    def _initialize_planner_agent(self):
        """åˆå§‹åŒ– PlannerAgent"""
        try:
            # è·å–é…ç½®
            max_iterations = self.config.get("agent.planner.max_iterations", 5)

            # åˆ›å»º LLM
            llm = self._create_llm()
            if llm is None:
                logger.warning("âš ï¸ Failed to create LLM, PlannerAgent disabled")
                return None

            # åˆ›å»ºé…ç½®
            config = AgentConfig(
                max_iterations=max_iterations,
                enable_memory=False,
            )

            # åˆ›å»º PlannerAgent
            agent = PlannerAgent(
                name="planner_agent",
                llm=llm,
                config=config,
            )

            logger.info("âœ… PlannerAgent initialized successfully")
            return agent

        except Exception as e:
            logger.error(f"âŒ Failed to initialize PlannerAgent: {e}")
            import traceback
            traceback.print_exc()
            return None

    def _create_llm(self):
        """åˆ›å»º LLM å®ä¾‹"""
        try:
            # å°è¯•ä»ä¸ƒç‰›äº‘é…ç½®åˆ›å»º
            qiniu_config = self.config.get("qiniu")
            if qiniu_config:
                llm = ChatOpenAI(
                    api_key=qiniu_config.get("api_key"),
                    base_url=qiniu_config.get("base_url"),
                    model=qiniu_config.get("llm", {}).get("model", "gpt-4o-mini"),
                    temperature=qiniu_config.get("llm", {}).get("temperature", 0.7),
                    max_tokens=qiniu_config.get("llm", {}).get("max_tokens", 2000),
                )

                logger.info("âœ… LLM created from Qiniu config")
                return llm

        except ImportError:
            logger.warning("âš ï¸ langchain_openai not installed")
        except Exception as e:
            logger.error(f"âŒ Failed to create LLM: {e}")

        return None

    def _execute_plan(self, plan_result: Dict[str, Any]) -> str:
        """
        æ‰§è¡Œä»»åŠ¡è®¡åˆ’

        å‚æ•°:
            plan_result: PlannerAgent è¿”å›çš„è®¡åˆ’ç»“æœ

        è¿”å›:
            æ‰§è¡Œç»“æœæè¿°
        """
        logger.info("âš™ï¸  Executing plan...")

        # 1. æ£€æŸ¥è®¡åˆ’æ˜¯å¦æˆåŠŸ
        if not plan_result.get("success"):
            return plan_result.get("message", "è§„åˆ’å¤±è´¥")

        # 2. è·å–è®¡åˆ’
        plan = plan_result.get("plan", {})

        # 3. æ£€æŸ¥å¯è¡Œæ€§
        feasibility = plan.get("feasibility", "unknown")

        if feasibility == "invalid_input":
            # todo äº¤ç»™ttsæ¨¡å‹è¾“å‡º
            return "æ‚¨çš„è¾“å…¥ä¼¼ä¹ä¸å¤Ÿæ¸…æ™°ï¼Œè¯·é‡æ–°è¡¨è¿°æ‚¨çš„éœ€æ±‚ã€‚"

        elif feasibility == "infeasible":
            # todo äº¤ç»™ttsæ¨¡å‹è¾“å‡º
            return "æŠ±æ­‰ï¼Œè¿™ä¸ªä»»åŠ¡æˆ‘ç›®å‰æ— æ³•å®Œæˆã€‚æˆ‘åªèƒ½æ‰§è¡Œè®¡ç®—æœºç›¸å…³çš„æ“ä½œã€‚"

        elif feasibility == "feasible":
            steps = plan.get("steps", [])
            if not steps:
                return "å·²æ”¶åˆ°æ‚¨çš„æŒ‡ä»¤ï¼Œä½†æš‚æ—¶æ— æ³•æ‰§è¡Œã€‚"

            # TODO: å®é™…æ‰§è¡Œæ­¥éª¤
            # è¿™é‡Œå¯ä»¥è°ƒç”¨å·¥å…·ç³»ç»Ÿæ‰§è¡Œå…·ä½“æ­¥éª¤
            logger.info(f"ğŸ“ Plan has {len(steps)} steps")
            logger.info("   (Actual execution to be implemented)")

            return f"æˆ‘å·²ç»ä¸ºæ‚¨è§„åˆ’äº† {len(steps)} ä¸ªæ­¥éª¤ï¼Œä½†ç›®å‰è¿˜ä¸æ”¯æŒè‡ªåŠ¨æ‰§è¡Œã€‚"

        else:
            return "æ”¶åˆ°æ‚¨çš„æŒ‡ä»¤ï¼Œä½†æ— æ³•ç¡®å®šå¦‚ä½•æ‰§è¡Œã€‚"

    def _text_to_speech(self, text: str):
        """æ–‡å­—è½¬è¯­éŸ³"""
        # TODO: è°ƒç”¨ TTS API
        logger.info("ğŸ”Š Providing voice feedback...")
        logger.info(f"ğŸ’¬ Response: {text}")
